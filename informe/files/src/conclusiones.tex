A lo largo de este informe, experimentamos con distintos algoritmos de aprendizaje automático y evaluamos sus respectivos rendimientos. En base a los datos obtenidos, se eligió el clasificador que para nosotros mejor aproxima la solución al problema y estudiamos su performance final. 

Creemos interesante aprovechar esta sección para mencionar algunos problemas con los que nos encontramos y proponer mejoras metodológicas para futuras investigaciones.

Uno de los aspectos sobre los cuales no profundizamos fue el hecho de normalizar o no los datos. Para algunos algoritmos, tales como \textit{SVM} o \textit{KNN}, se sabe que hacerlo puede tener una implicancia importante sobre los resultados. Durante las etapas de entrenamiento y validación exploramos esta dimensión, pero optamos por no incluirla al no mejorar los resultados. Esto igualmente podría ser un error de nuestra parte, ya que a pesar de arrojar peores resultados tal vez conduce a modelos más robustos.

A su vez, nunca se le dió un enfoque a realizar un análisis previo del dataset recibido, tal como apreciar la distribución de los atributos (por ejemplo a través de histogramas). Nosotros realizamos en forma exploratoria un pequeño análisis respecto a estas distribuciones observando un resumen estadístico, donde notamos una media por lo general rondando el $0$ y algunos indicios de que las mismas se comportarían de manera normal. Consideramos que en futuras investigaciones deberíamos de realizar una exploración mayor respecto a los atributos con los que contamos, por ejemplo a través de un análisis de sus importancias.

Por otro lado, no se contempló si la métrica \textit{auc roc} promedio es la más indicada para el dominio de este problema. Por ejemplo, \cite{Saito} recomienda usar la métrica \textit{auprc} cuando la proporción de las clases es desbalanceada, como es en este caso. Esto está también relacionado a cuál es la clase positiva. Si bien no se investigó si convendría utilizar el \textit{mal pronóstico}, al menos sabemos que la métrica \textit{auc roc} es más imparcial respecto a cuál de las clases representa la etiqueta. Estas elecciones son muy importantes y futuras investigaciones deberían abordarlas a mayor consciencia.

Por último, vale la pena mencionar las limitaciones de la manera en la que realizamos la búsqueda de los hiperparámetros. Consideramos que la cantidad de iteraciones realizada fue baja respecto a los espacios de búsqueda que decidimos explorar. A su vez, es muy posible que existan mejores métodos de sampleo que aquellos que empleamos. Otro aspecto que no fue explorado fue la posibilidad de realizar una búsqueda en cuadrícula en vez de aleatoria, sobre todo para los hiperparámetros cuyos valores son discretos. Creemos que una mejor investigación pondría mayor énfasis en los métodos a través de los cuales realizar este tipo de búsquedas.