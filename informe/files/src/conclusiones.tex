A lo largo de este informe, experimentamos con distintos algoritmos de aprendizaje automático y evaluamos sus respectivos rendimientos. En base a los datos obtenidos, se eligió el clasificador que para nosotros mejor aproxima la solución al problema y estudiamos su performance final. 

Creemos interesante aprovechar esta sección para mencionar algunos problemas con los que nos encontramos y proponer mejoras metodológicas para futuras investigaciones.

Uno de los aspectos sobre los cuales no profundizamos fue el hecho de normalizar o no los datos. Para algunos algoritmos, tales como \textit{support vector machines} y \textit{k-nearest neighbours}, se sabe que hacerlo puede tener una implicancia importante sobre los resultados. Durante las etapas de entrenamiento y validación exploramos esta dimensión, pero optamos por no incluirla ya que no parecía mejorar los resultados. Esto podría ser un error de nuestra parte, ya que, a pesar de arrojar peores resultados, podría conducir a modelos más robustos.

A su vez, no nos enfocamos en realizar un análisis previo del dataset. Por ejemplo, investigar cómo se distribuyen los atributos. Lo único que realizamos ---de manera exploratoria--- fue un pequeño análisis basado en un resumen estadístico. En el mismo, notamos una media ---de manera general para todos los atributos--- rondando el $0$ y, a su vez, algunos indicios que reflejarían que los mismos se comportan de manera normal. Consideramos que en futuras investigaciones deberíamose realizar una exploración mayor respecto a los atributos con los que contamos, por ejemplo a través de un análisis de sus importancias.

Por otro lado, no se contempló si la métrica \textit{aucroc} promedio es la más indicada para el dominio de este problema. Por ejemplo, \cite{Saito} recomienda usar la métrica \textit{auprc} cuando la proporción de las clases es desbalanceada, como sucede en este caso. Esto está también relacionado a cuál es la clase positiva. Si bien no se investigó si convendría utilizar el \textit{mal pronóstico}, al menos sabemos que la métrica \textit{aucroc} es más imparcial respecto a cuál de las clases representa la etiqueta. Estas elecciones son muy importantes y futuras investigaciones deberían abordarlas con mayor consciencia.

Por último, vale la pena mencionar las limitaciones en la manera en que realizamos la búsqueda de los hiperparámetros. Consideramos que la cantidad de iteraciones realizada fue baja respecto a los espacios de búsqueda que decidimos explorar. A su vez, es muy posible que existan mejores métodos de sampleo que aquellos que empleamos. Otro aspecto que no fue explorado fue la posibilidad de realizar una búsqueda en cuadrícula en vez de aleatoria, sobre todo para los hiperparámetros cuyos valores son discretos. Creemos que una mejor investigación pondría mayor énfasis en los métodos a través de los cuales realizar este tipo de exploraciones.